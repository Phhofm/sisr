#!/usr/bin/env python3
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# JPEG Blockiness Artifact Detector
# 
# Script generated by Philip Hofmann using DeepSeek AI Assistant
#
# Based on:
# Bhardwaj, Dinesh, and Vinod Pankajakshan. "A JPEG blocking artifact detector 
# for image forensics." Signal Processing: Image Communication 68 (2018): 155-161.
#
# Features:
# - Detects JPEG compression artifacts in images
# - Supports multiple formats: JPG, JPEG, PNG, WebP
# - Parallel processing for efficiency
# - Robust error handling
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

import numpy as np
import cv2
from tqdm import tqdm
import os
import argparse
from basicsr.utils import scandir
from concurrent.futures import ProcessPoolExecutor
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Constants
BLOCK_SIZE = 8           # Standard JPEG block size
MIN_BLOCKS = 3           # Minimum blocks required in each dimension
EPSILON = 1e-10          # Small value to prevent division by zero
SUPPORTED_EXTENSIONS = ('.jpg', '.jpeg', '.webp', '.png')  # Supported image formats

class DCTProcessor:
    """
    Efficient 2D Discrete Cosine Transform (DCT) processor.
    
    Precomputes the DCT basis matrix for fast transformation of 8x8 blocks.
    Implements the standard DCT-II formulation used in JPEG compression.
    """
    def __init__(self, block_size: int = BLOCK_SIZE):
        self.block_size = block_size
        # Precompute and cache the DCT basis matrix
        self.basis_matrix = self._create_basis_matrix()
    
    def _create_basis_matrix(self) -> np.ndarray:
        """Construct the DCT basis matrix for efficient transformation."""
        basis_vectors = []
        # Generate basis vectors for all frequency components
        for u in range(self.block_size):
            for v in range(self.block_size):
                basis = self._compute_basis_vector(u, v)
                basis_vectors.append(basis.flatten())
        return np.vstack(basis_vectors)
    
    def _compute_basis_vector(self, u: int, v: int) -> np.ndarray:
        """
        Compute a single DCT basis vector for frequency components (u, v).
        
        Args:
            u: Horizontal frequency component (0 to block_size-1)
            v: Vertical frequency component (0 to block_size-1)
            
        Returns:
            2D basis vector of shape (block_size, block_size)
        """
        # Create coordinate grids
        x, y = np.mgrid[:self.block_size, :self.block_size]
        # Normalization factor
        scale = 1.0 / np.sqrt(2 * self.block_size)
        
        # Special cases for DC and low-frequency components
        if u == 0 and v == 0:
            # DC component (constant)
            return np.ones((self.block_size, self.block_size)) * scale
        elif u == 0:
            # Horizontal AC components
            return scale * np.sqrt(2) * np.cos((2*y + 1) * v * np.pi / (2 * self.block_size))
        elif v == 0:
            # Vertical AC components
            return scale * np.sqrt(2) * np.cos((2*x + 1) * u * np.pi / (2 * self.block_size))
        # General AC components
        return 2 * scale * np.cos((2*x + 1) * u * np.pi / (2 * self.block_size)) * \
               np.cos((2*y + 1) * v * np.pi / (2 * self.block_size))

    def dct2(self, block: np.ndarray) -> np.ndarray:
        """
        Apply 2D DCT to an 8x8 block using matrix multiplication.
        
        Args:
            block: 8x8 pixel block
            
        Returns:
            8x8 DCT coefficient block
        """
        return np.dot(self.basis_matrix, block.flatten()).reshape(self.block_size, self.block_size)

def calc_valid_dimension(dim: int) -> int:
    """
    Calculate largest dimension that is multiple of BLOCK_SIZE.
    
    This ensures we can divide the image into complete blocks without remainder.
    """
    return dim - (dim % BLOCK_SIZE)

def image_to_blocks(img: np.ndarray) -> np.ndarray:
    """
    Convert image to 4D block array for efficient processing.
    
    Reshapes image into [num_blocks_y, num_blocks_x, BLOCK_SIZE, BLOCK_SIZE]
    """
    h, w = img.shape
    h_blocks = h // BLOCK_SIZE
    w_blocks = w // BLOCK_SIZE
    # Crop to exact multiple of block size and reshape
    return img[:h_blocks*BLOCK_SIZE, :w_blocks*BLOCK_SIZE].reshape(
        h_blocks, BLOCK_SIZE, w_blocks, BLOCK_SIZE
    ).transpose(0, 2, 1, 3)  # Reorder to [h_blocks, w_blocks, BLOCK_SIZE, BLOCK_SIZE]

def compute_dct_blocks(blocks: np.ndarray, dct_processor: DCTProcessor) -> np.ndarray:
    """Apply DCT to all blocks in the image using the precomputed basis matrix."""
    dct_blocks = np.empty_like(blocks)
    # Process each block individually
    for i in range(blocks.shape[0]):
        for j in range(blocks.shape[1]):
            dct_blocks[i, j] = dct_processor.dct2(blocks[i, j])
    return dct_blocks

def compute_blockiness_measure(dct_blocks: np.ndarray) -> np.ndarray:
    """
    Compute the blocking artifact measure V.
    
    Measures the difference between a block and its neighbors in both directions.
    Returns the average measure per coefficient position.
    """
    # Validate block dimensions
    if dct_blocks.shape[0] < MIN_BLOCKS or dct_blocks.shape[1] < MIN_BLOCKS:
        return np.zeros((BLOCK_SIZE, BLOCK_SIZE))
    
    # Extract inner blocks (away from image borders)
    center = dct_blocks[1:-1, 1:-1]  # [i, j] blocks
    left = dct_blocks[1:-1, 0:-2]    # [i, j-1] blocks
    right = dct_blocks[1:-1, 2:]     # [i, j+1] blocks
    top = dct_blocks[0:-2, 1:-1]     # [i-1, j] blocks
    bottom = dct_blocks[2:, 1:-1]     # [i+1, j] blocks

    # Compute horizontal and vertical differences
    horizontal_diff = left + right - 2 * center
    vertical_diff = top + bottom - 2 * center
    
    # Calculate artifact measure V
    V = np.sqrt(horizontal_diff**2 + vertical_diff**2)
    
    # Average across all blocks
    return np.mean(V, axis=(0, 1))

def compute_blockiness_score(image: np.ndarray) -> float:
    """Compute the blockiness score for a grayscale image."""
    # Validate minimum image size
    if image.shape[0] < 3 * BLOCK_SIZE or image.shape[1] < 3 * BLOCK_SIZE:
        raise ValueError(f"Image too small: {image.shape}")
    
    dct_processor = DCTProcessor()
    
    # Process original image (aligned with JPEG grid)
    valid_h = calc_valid_dimension(image.shape[0])
    valid_w = calc_valid_dimension(image.shape[1])
    orig_blocks = image_to_blocks(image[:valid_h, :valid_w])
    
    # Validate block count
    if orig_blocks.shape[0] < MIN_BLOCKS or orig_blocks.shape[1] < MIN_BLOCKS:
        raise ValueError(f"Insufficient blocks: {orig_blocks.shape[:2]}")
    
    # Compute DCT and artifact measure
    dct_orig = compute_dct_blocks(orig_blocks, dct_processor)
    V_orig = compute_blockiness_measure(dct_orig)
    
    # Process shifted image (4px offset to avoid JPEG grid alignment)
    shifted = image[4:, 4:]
    valid_h2 = calc_valid_dimension(shifted.shape[0])
    valid_w2 = calc_valid_dimension(shifted.shape[1])
    shifted_blocks = image_to_blocks(shifted[:valid_h2, :valid_w2])
    
    # Validate shifted block count
    if shifted_blocks.shape[0] < MIN_BLOCKS or shifted_blocks.shape[1] < MIN_BLOCKS:
        raise ValueError(f"Insufficient shifted blocks: {shifted_blocks.shape[:2]}")
    
    # Compute DCT and artifact measure for shifted image
    dct_shifted = compute_dct_blocks(shifted_blocks, dct_processor)
    V_shifted = compute_blockiness_measure(dct_shifted)
    
    # Compute blockiness score as normalized difference
    with np.errstate(divide='ignore', invalid='ignore'):
        # Absolute relative difference between aligned and shifted artifacts
        D_matrix = np.abs((V_shifted - V_orig) / (V_orig + EPSILON))
    
    # Sum differences to get final blockiness score
    return np.sum(D_matrix)

def load_image(img_path: str) -> np.ndarray:
    """Load an image and convert to grayscale with proper color handling."""
    # Read image preserving original channels
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        raise IOError(f"Unable to read image: {img_path}")
    
    # Handle different color formats
    if img.ndim == 3:
        channels = img.shape[2]
        if channels == 4:  # BGRA or RGBA
            return cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)
        elif channels == 3:  # BGR or RGB
            return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            raise ValueError(f"Unsupported color channels: {channels}")
    elif img.ndim == 2:
        return img  # Already grayscale
    raise ValueError(f"Invalid image dimensions: {img.ndim}")

def process_image(img_path: str) -> tuple:
    """Process an image to calculate its blockiness score."""
    try:
        # Load and convert to grayscale
        gray_img = load_image(img_path)
        # Compute blockiness score
        score = compute_blockiness_score(gray_img)
        return img_path, float(score)
    except Exception as e:
        logger.error(f"Error processing {img_path}: {str(e)}")
        return img_path, None

def main():
    # Command-line interface setup
    parser = argparse.ArgumentParser(
        description="Detect JPEG Blocking Artifacts in Images",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('-i', '--input', required=True, 
                        help="Directory containing input images")
    parser.add_argument('-o', '--output', required=True,
                        help="Output file for blockiness scores")
    parser.add_argument('-e', '--extensions', default='jpg,jpeg,png,webp',
                        help="Comma-separated file extensions to process")
    parser.add_argument('--start_idx', type=int, default=0,
                        help="Starting index in sorted file list")
    parser.add_argument('--end_idx', type=int, default=100000000,
                        help="Ending index in sorted file list")
    parser.add_argument('-w', '--workers', type=int, default=os.cpu_count(),
                        help="Number of parallel worker processes")
    args = parser.parse_args()

    # Prepare extensions list
    extensions = []
    for ext in args.extensions.split(','):
        ext = ext.strip().lower()
        if ext and not ext.startswith('.'):
            ext = '.' + ext
        if ext:
            extensions.append(ext)
    
    if not extensions:
        extensions = list(SUPPORTED_EXTENSIONS)
    
    logger.info(f"Processing extensions: {', '.join(extensions)}")

    # Discover image paths
    all_paths = []
    for ext in extensions:
        all_paths.extend(scandir(args.input, suffix=ext, recursive=True))
    all_paths = sorted(all_paths)
    paths = all_paths[args.start_idx:args.end_idx]
    full_paths = [os.path.join(args.input, p) for p in paths]
    
    logger.info(f"Found {len(full_paths)} images to process")
    logger.info(f"Using {args.workers} worker processes")
    
    # Process images in parallel
    with open(args.output, 'w') as out_file:
        with ProcessPoolExecutor(max_workers=args.workers) as executor:
            # Setup progress bar
            results = tqdm(
                executor.map(process_image, full_paths),
                total=len(full_paths),
                desc="Processing images"
            )
            
            # Write results as they complete
            for img_path, score in results:
                if score is not None:
                    out_file.write(f"{img_path}\t{score}\n")
                    out_file.flush()

    logger.info(f"Processing complete. Results saved to {args.output}")

if __name__ == "__main__":
    main()